import requests
from bs4 import BeautifulSoup
import pandas as pd

def juegoLimpio(soup):
  tabla= soup.find("table", {"style": "background: #006699; border: 1px #aaa solid; border-collapse: collapse; font-size: 95%;"})
  filas= tabla.find_all("tr")
  encabezados= [th.get_text(strip=True) for th in filas[0].find_all("th")]
  datos=[]
  for fila in filas[1:]:
    celdas= fila.fins_all(["th", "td"])
    datos.append([celda.get_text(strip=True) for celda in celdas])
  df= pd.DataFrame(datos, columns= encabezados)
  df.insert(0, "ID", range(801, 801 + len(df)))
  return df

def goleadoras(soup):
  tabla= soup.find("table", {"style": "background: #E6EEE6; border: 1px #aaa solid; border-collapse: collapse; font-size: 85%;"})
  filas= tabla.find_all("tr")
  encabezados= [th.get_text(strip=True) for th in filas [0].find_all("th")]
  datos=[]
  for fila in filas[1:]:
    celdas= fila.find_all(["th","td"])
    datos.append([celda.get_text(strip=True) for celda in celdas])
  df= pd.DataFrame(datos, columns= encabezados)
  df.insert(0, "ID", range(901, 901 + len(df)))
  return df

def scrapjornada(url, jornada, df):
  #Obtener contenido de la pag
  link = requests.get(url)
  soup = BeautifulSoup(link.content, "html.parser")

  #Encontrar tabla
  tabla = soup.find("table", {"class": "ctr-stadistics-header__table"})

  #Listas para guardar los datos
  positions= []
  teams = []
  jj= []
  jg= []
  je= []
  jp= []
  gf= []
  gc= []
  dg = []
  pts = []

  #Buscar entre las filas
  for row in tabla.find_all("tr")[1:]:
    columnas = row.find_all("td")
    positions.append(columnas[0].text.strip())
    teams.append(columnas[1].text.strip())
    jj.append(columnas[2].text.strip())
    jg.append(columnas[3].text.strip())
    je.append(columnas[4].text.strip())
    jp.append(columnas[5].text.strip())
    gf.append(columnas[6].text.strip())
    gc.append(columnas[7].text.strip())  
    dg.append(columnas[8].text.strip())
    pts.append(int(columnas[9].text.strip()))

  data = {
    "Posicion": positions,
    "Equipo": teams,
    "JJ": jj,
    "JG": jg,
    "JE": je,
    "JP": jp,
    "GF": gf,
    "GC": gc,
    "DG": dg,
    "PTS": pts,
    "Jornada": [jornada] * len(positions)
  }

#ligas de las jornadas
urls = [
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/1", "1"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/2", "2"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/3", "3"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/4", "4"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/5", "5"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/6", "6"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/7", "7"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/8", "8"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/9", "9"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/10", "10"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/11", "11"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/12", "12"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/13", "13"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/14", "14"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/15", "15"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/16", "16"),
  ("https://www.mediotiempo.com/futbol/liga-mx-femenil/tabla-general/5s134eik-2023/regular/17", "17"),
]

losdatos= pd.DataFrame()
for url, jornada in urls:
  losdatos = scrapjornada(url, jornada, losdatos)
losdatos["PTS"] = losdatos["PTS"].astype(int)
losdatos["PTS_Anterior"] = losdatos.groupby("Equipo")["PTS"].shift(1, fill_value=0)
losdatos["PTS_Ganados"] = losdatos["PTS"] - losdatos["PTS_Anterior"]
losdatos= losdatos.drop(columns=["PTS_Anterior"])
losdatos["Id_Jornadas"] = range(1, len(losdatos) + 1)
losdatos.to_csv("Jornadas_2023.csv", index=False)
print("Se han guardado todas las jornadas en 'Jornadas_2023.csv'")
dfJornadas= pd.read_csv("Jornadas_2023.csv")
print(dfJornadas)

pg_jornada_data= losdatos[["Equipo", "PTS_Ganados", "Jornada"]].copy()
pg_jornada_data.rename(columns= {"Equipo": "Id_Equipo"}, inplace=True)
pg_jornada_data["Id"] = range (201, 201 + len(pg_jornada_data))
pg_jornada_data.to_csv("PG_Jornada.csv", index=False)
print("Se han guardado los puntos ganados por jornada en 'PG_Jornada.csv'")
print(pg_jornada_data)
dfPG= pd.read_csv("PG_Jornada.csv")
print(dfPG)

progreso_data= losdatos.groupby(["Equipo", "Jornada"]).agg({
  "JJ": "max",
  "JG": "max",
  "JE": "max",
  "JP": "max"
}).reset_index()

progreso_data.columns=["Equipo", "Jornada", "Juegos Jugados", "Juegos Ganados", "Juegos Empatados", "Juegos Perdidos"]
progreso_data["Id"] = range(301, 301 + len(progreso_data))
progreso_data.to_csv("Progreso_porJornada.csv", index= False)
print("Se ha guardado la tabla de progreso de puntos por jornada 'Progreso_porJornada.csv'")
dfProg= pd.read_csv("Progreso_porJornada.csv")
print(dfProg)

wk_link= "https://es.wikipedia.org/wiki/Torneo_Apertura_2023_(Liga_MX_Femenil)"
link2= requests.get(wk_link)
soup= BeautifulSoup(link2.content, "html.parser")
clas_JuegoLimpio= juegoLimpio(soup)
print("Tabla de Clasificación de Juego Limpio: ")
print(clas_JuegoLimpio)
clas_JuegoLimpio.to_csv("clasificacion_juego_limpio.csv", index=False)
dfjuglimp= pd.read_csv("clasificacion_juego_limpio.csv")
print(dfjuglimp)
topgoleadoras=goleadoras(soup)
print("\nTabla de Máximas Goleadoras: ")
topgoleadoras.to_csv("maximas_goleadoras.csv", index=False)
dfgoleadoras= pd.read_csv("maximas_goleadoras.csv")
print(dfgoleadoras)
